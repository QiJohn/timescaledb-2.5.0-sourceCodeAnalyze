==================================重复数据删除方法(1)===============================================================
    去重的方法一般是找到重复数据中的一条，以某一唯一条件去掉其他重复值。PG中也有一个唯一字段ctid，也可以根据此来做,如果表里设置了oid,数据量不大的情况下也可以。当然如果
表中有唯一的序列值，就更方便了
    postgres=# create table test(id int,name varchar);
    CREATE TABLE
    postgres=# insert into test values (1,'kenyon');
    INSERT 0 1
    postgres=# insert into test values (1,'kenyon');
    INSERT 0 1
    postgres=# insert into test values (1,'kenyon');
    INSERT 0 1
    postgres=# insert into test values (2,'kenyon_test');
    INSERT 0 1
    postgres=# insert into test values (2,'kenyon_test');
    INSERT 0 1
    postgres=# insert into test values (3,'test');
    INSERT 0 1
    postgres=# insert into test values (5,'test');
    INSERT 0 1
    postgres=# insert into test values (5,'jackson');
    INSERT 0 1

    postgres=# select ctid,* from test;
    ctid  | id |    name     
    -------+----+-------------
     (0,1) |  1 | kenyon
     (0,2) |  1 | kenyon
     (0,3) |  1 | kenyon
     (0,4) |  2 | kenyon_test
     (0,5) |  2 | kenyon_test
     (0,6) |  3 | test
     (0,7) |  5 | test
     (0,8) |  5 | jackson
    (8 rows)
    
查询要保留的数据,以min(ctid)或max(ctid)为准
    postgres=# select ctid,* from test where ctid in (select min(ctid) from test group by id);
     ctid  | id |    name     
    -------+----+-------------
    (0,1) |  1 | kenyon
    (0,4) |  2 | kenyon_test
    (0,6) |  3 | test
    (0,7) |  5 | test
    (4 rows)
删除重复数据,查看最后结果
    postgres=# delete from test where ctid not in (select min(ctid) from test group by id);
    DELETE 4
    postgres=# select ctid,* from test;
    ctid  | id |    name     
    -------+----+-------------
    (0,1) |  1 | kenyon
    (0,4) |  2 | kenyon_test
    (0,6) |  3 | test
    (0,7) |  5 | test
    (4 rows)
如果表中已经有标明唯一的序列主键值，可以把该值替换上述的ctid直接删除。








==================================重复数据删除方法(2)===============================================================
    例如使用第三方工具进行数据备份时，备份过程中删除重复数据。该类工具删除重复数据的核心原理为：
    
    重复数据删除在整个 FlexVol® 卷以及聚合中的所有卷中以 4KB 块级别运行，可消除重复的数据块并仅存储唯一的数据块。
    重复数据删除的核心支持技术是指纹 — 所有 4 KB 数据块的唯一数字签名。
    将数据写入系统时，实时重复数据删除引擎会扫描传入的块，创建指纹并将指纹存储在哈希存储中（内存数据结构）。
    计算指纹后，将在哈希存储中执行查找。在哈希存储中找到匹配的指纹后，将在缓存中搜索与重复指纹（主数据块）对应的数据块：
    如果找到此参数，则会对当前数据块（接收方块）和源块进行逐字节比较，以进行验证，以确保完全匹配。验证后，该接收方块将与匹配的接收方块共享，而不会将该接收方块实际
写入磁盘。仅更新元数据以跟踪共享详细信息。如果在缓存中未找到源块，则会将此源块从磁盘预提取到缓存中，以执行逐字节比较，以确保完全匹配。验证后，接收方块会被标记为重
复，但不会实际写入磁盘。元数据会更新，用于跟踪共享详细信息。后台重复数据删除引擎的工作方式相同。它会扫描聚合中的所有数据块，并通过比较这些数据块的指纹以及逐字节比
较来消除重复数据，从而消除任何误报。此过程还可确保重复数据删除操作期间不会丢失任何数据。









